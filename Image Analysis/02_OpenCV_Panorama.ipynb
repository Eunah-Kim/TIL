{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파노라마 사진 생성\n",
    "### (1) 좌측 사진을 우측사진에 매칭\n",
    "### (2) 원근변환 행렬을 구하여, cv2.warpPerspective() 함수로 원근 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good matches:62/500\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "#이미지 불러오기\n",
    "img1 = cv2.imread('img/restaurant1.jpg')\n",
    "img2 = cv2.imread('img/restaurant2.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 검출기 생성\n",
    "detector = cv2.ORB_create()\n",
    "kp1, desc1  = detector.detectAndCompute(gray2, None)\n",
    "kp2, desc2  = detector.detectAndCompute(gray1, None)\n",
    "\n",
    "# 매칭기 생성\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "\n",
    "# 매칭(knnMatch 이용)\n",
    "matches = matcher.knnMatch(desc1, desc2 , 2)\n",
    "# print(\"matches: \", matches)\n",
    "# print(\" \")\n",
    "\n",
    "# 이웃 거리의 75%로 좋은 매칭점 추출---②\n",
    "ratio = 0.7\n",
    "good_matches = [first for first,second in matches \\\n",
    "                    if first.distance < second.distance * ratio]\n",
    "print('good matches:%d/%d' %(len(good_matches),len(matches)))\n",
    "\n",
    "# 좋은 매칭점의 queryIdx로 원본 영상의 좌표 구하기 ---③\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ])\n",
    "    \n",
    "# 좋은 매칭점의 trainIdx로 대상 영상의 좌표 구하기 ---④\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ])\n",
    "\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "\n",
    "# 원본 영상 크기로 변환 영역 좌표 생성 ---⑥\n",
    "w = img2.shape[1] + img1.shape[1]\n",
    "h = img2.shape[0]\n",
    "\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "\n",
    "# 원본 영상 좌표를 원근 변환  ---⑦\n",
    "dst = cv2.perspectiveTransform(pts, mtrx)\n",
    "\n",
    "dst = cv2.warpPerspective(img2, mtrx, (w, h))\n",
    "\n",
    "dst[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "cv2.imshow('Good Match', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: 40/274, min: 12.00, max: 90.00, thresh: 27.60\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#이미지 불러오기\n",
    "img1 = cv2.imread('img/restaurant1.jpg')\n",
    "img2 = cv2.imread('img/restaurant2.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 검출기 생성\n",
    "detector = cv2.ORB_create()\n",
    "kp1, des1 = detector.detectAndCompute(gray2, None)\n",
    "kp2, des2 = detector.detectAndCompute(gray1, None)\n",
    "\n",
    "# 매칭기 생성\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "# 매칭\n",
    "matches = matcher.match(des1, des2)\n",
    "\n",
    "\n",
    "# 좋은 매칭점 찾기\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "min_dist, max_dist = matches[0].distance, matches[-1].distance\n",
    "\n",
    "ratio = 0.2\n",
    "good_thresh = (max_dist - min_dist)*ratio + min_dist\n",
    "\n",
    "good_matches = [m for m in matches if m.distance < good_thresh]\n",
    "print('matches: %d/%d, min: %.2f, max: %.2f, thresh: %.2f' %(len(good_matches),len(matches), min_dist, max_dist, good_thresh))\n",
    "\n",
    "# 원근변환\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ])\n",
    "\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ])\n",
    "\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "\n",
    "w = img1.shape[1] + img2.shape[1]\n",
    "h = img1.shape[0]\n",
    "\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "\n",
    "res = cv2.cv2.warpPerspective(img2, mtrx, (w, h))\n",
    "\n",
    "res[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "cv2.imshow('goodMatch', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
